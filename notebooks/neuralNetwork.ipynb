{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597212920109",
   "display_name": "Python 3.8.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import Variable, ones, keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Simple Dense Layer\n",
    "Dense layer = one of the hidden layers in a neural network\n",
    "\n",
    "This notebook demonstrates creating a single dense layer with the following architecture\n",
    "\n",
    "![img](./simpleANN.png)\n",
    "\n",
    "Note that:\n",
    "* Random weights are usually assigned at the start\n",
    "* Bias are often first initialised as ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "borrower_features = tf.constant([\n",
    "        [ 3.,  3., 23.],\n",
    "        [ 2.,  1., 24.],\n",
    "        [ 1.,  1., 49.],\n",
    "        [ 1.,  1., 49.],\n",
    "        [ 2.,  1., 29.]\n",
    "    ], tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Tensorflow's low level apis\n",
    "\n",
    "When every math of the neural network is coded by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(\n[[0.95257413]\n [0.95257413]\n [0.95257413]\n [0.95257413]\n [0.95257413]], shape=(5, 1), dtype=float32)\n"
    }
   ],
   "source": [
    "# Assuming now there are 5 examples provided\n",
    "# and 3 features are still used for the prediction\n",
    "bias1 = Variable(1.0)\n",
    "weights1 = Variable(tf.ones((3, 2)))\n",
    "products1 = matmul(borrower_features, weights1)\n",
    "dense1 = keras.activations.sigmoid(products1 + bias1)\n",
    "\n",
    "bias2 = Variable(1.0)\n",
    "weights2 = Variable(ones((2, 1)))\n",
    "products2 = matmul(dense1, weights2)\n",
    "dense2 = keras.activations.sigmoid(products2 + bias2)\n",
    "\n",
    "print(dense2) # Output should contain 5 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Tensorflow's high level api\n",
    "\n",
    "Utilising `tf.keras.layers.Dense`, we can replicate the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(\n[[0.95257413]\n [0.95257413]\n [0.95257413]\n [0.95257413]\n [0.95257413]], shape=(5, 1), dtype=float32)\n"
    }
   ],
   "source": [
    "weights1 = tf.initializers.Ones()\n",
    "bias1 = tf.initializers.Ones()\n",
    "weights2 = tf.initializers.Ones()\n",
    "bias2 = tf.initializers.Ones()\n",
    "\n",
    "denseTF1 = tf.keras.layers.Dense(\n",
    "            units=2,\n",
    "            activation='sigmoid',\n",
    "            use_bias=True,\n",
    "            kernel_initializer=weights1,\n",
    "            bias_initializer=bias1\n",
    "        )(borrower_features)\n",
    "\n",
    "denseTF2 = keras.layers.Dense(\n",
    "            units=1,\n",
    "            activation='sigmoid',\n",
    "            use_bias=True,\n",
    "            kernel_initializer=weights2,\n",
    "            bias_initializer=bias2\n",
    "        )(denseTF1)\n",
    "print(denseTF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}